
import requests

import os

import html

import difflib

import time

from datetime import datetime



# ==========================================

# ğŸ”‘ API í‚¤ ì„¤ì •

# ==========================================

NAVER_CLIENT_ID = "2cC4xeZPfKKs3BVY_onT"

NAVER_CLIENT_SECRET = "21DmUYrAdX"



if os.environ.get("NAVER_CLIENT_ID"):

    NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")

    NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")



def crawl_naver_news_api(target_keywords, excludes=[], display_limit=50):

    """

    íŠ¹ì • í‚¤ì›Œë“œ ê·¸ë£¹ì— ëŒ€í•´ì„œë§Œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜

    """

    url = "https://openapi.naver.com/v1/search/news.json"

    

    headers = {

        "X-Naver-Client-Id": NAVER_CLIENT_ID,

        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET

    }

    

    # í•´ë‹¹ ê·¸ë£¹ì˜ í‚¤ì›Œë“œë¡œ ì¿¼ë¦¬ ìƒì„±

    query = " | ".join(target_keywords)

    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: [{query}] (ìš”ì²­ {display_limit}ê±´)")



    results = []

    

    # API í˜¸ì¶œ íšŸìˆ˜ ê³„ì‚° (1íšŒ ìµœëŒ€ 100ê°œ)

    loop_count = (display_limit // 100) + 1 if display_limit % 100 != 0 else (display_limit // 100)

    

    for i in range(loop_count):

        req_display = 100 if display_limit > 100 else display_limit

        display_limit -= req_display

        

        start = (i * 100) + 1

        

        params = {

            "query": query,

            "display": req_display,

            "start": start,

            "sort": "date"

        }



        try:

            response = requests.get(url, headers=headers, params=params)

            if response.status_code != 200:

                print(f"âŒ API í˜¸ì¶œ ì—ëŸ¬: {response.status_code}")

                break



            items = response.json().get('items', [])

            if not items: break



            for item in items:

                raw_title = item['title']

                clean_title = html.unescape(raw_title).replace("<b>", "").replace("</b>", "")

                

                raw_desc = item['description']

                clean_desc = html.unescape(raw_desc).replace("<b>", "").replace("</b>", "")

                

                link = item['originallink'] if item['originallink'] else item['link']



                # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬

                if any(ex_word in clean_title for ex_word in excludes):

                    continue



                # 2. í•„ìˆ˜ í‚¤ì›Œë“œ ì²´í¬ (ì œëª© ê¸°ì¤€)

                if not any(key_word in clean_title for key_word in target_keywords):

                    continue

                

                results.append({'title': clean_title, 'url': link, 'desc': clean_desc})

            

            time.sleep(0.3) 



        except Exception as e:

            print(f"âš ï¸ ì—ëŸ¬: {e}")

            break

            

    print(f"   ğŸ‘‰ ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")

    return results



def remove_duplicates_globally(all_news):

    """

    í•©ì³ì§„ ì „ì²´ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µ(URL ë° ë‚´ìš©)ì„ ì œê±°

    """

    unique_news = []

    seen_urls = set()

    seen_descriptions = []



    print("ğŸ§¹ ì „ì²´ ì¤‘ë³µ ì œê±° ë° ì •ì œ ì‘ì—… ì¤‘...")



    for item in all_news:

        # URL ì¤‘ë³µ ì²´í¬

        if item['url'] in seen_urls:

            continue

            

        # ë³¸ë¬¸ ë‚´ìš© ìœ ì‚¬ë„ ì²´í¬ (30ì ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µ ì²˜ë¦¬)

        is_content_dup = False

        for exist_desc in seen_descriptions:

            matcher = difflib.SequenceMatcher(None, item['desc'], exist_desc)

            match = matcher.find_longest_match(0, len(item['desc']), 0, len(exist_desc))

            

            if match.size >= 20: 

                is_content_dup = True

                break

        

        if is_content_dup:

            continue



        seen_urls.add(item['url'])

        seen_descriptions.append(item['desc'])

        unique_news.append(item)



    print(f"âœ… ìµœì¢… ë¦¬í¬íŠ¸ í¬í•¨ ê¸°ì‚¬: {len(unique_news)}ê±´")

    return unique_news



def format_news_report(news_data):

    sector_invest = []   # <íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>

    sector_industry = [] # <ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>



    for item in news_data:

        title = item['title']

        

        # íˆ¬ì/ì‹œì¥ ì„¹í„°ë¡œ ë³´ë‚¼ í‚¤ì›Œë“œ

        invest_keywords = ['ì†ìµ', 'ì‹¤ì ', 'íˆ¬ì', 'IR', 'ë‰´ìš•ì¦ì‹œ', 'ì½”ìŠ¤í”¼', 'ë§ˆê°', 'ì‹œí™©', 'ì£¼ê°€', 'ì¦ì‹œ']

        

        if any(k in title for k in invest_keywords):

            sector_invest.append(item)

        else:

            sector_industry.append(item)

    

    today = datetime.now().strftime("%Y-%m-%d")

    report = f"â–  News feed: {today}\n"

    

    report += "\n<ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>\n"

    if not sector_industry: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"

    for item in sector_industry:

        report += f"â€¢ {item['title']}\n{item['url']}\n\n"

        

    report += "<íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>\n"

    if not sector_invest: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"

    for item in sector_invest:

        report += f"â€¢ {item['title']}\n{item['url']}\n\n"

        

    return report



def send_telegram(message):

    token = os.environ.get('TELEGRAM_BOT_TOKEN')

    chat_id = os.environ.get('TELEGRAM_CHAT_ID')

    

    if not token or not chat_id:

        print("ğŸ”” í…”ë ˆê·¸ë¨ ì„¤ì • ì—†ìŒ (ì½˜ì†” ì¶œë ¥)")

        return



    try:

        url = f"https://api.telegram.org/bot{token}/sendMessage"

        data = {

            'chat_id': chat_id, 

            'text': message, 

            'disable_web_page_preview': True

        }

        requests.post(url, data=data)

        print("ğŸš€ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ")

    except Exception as e:

        print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")



if __name__ == "__main__":

    # ------------------------------------------------

    # 1. í‚¤ì›Œë“œ ê·¸ë£¹ ì •ì˜

    # ------------------------------------------------

    KEYWORDS_INSURANCE = ["ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ìƒë³´ì‚¬", "ë³´í—˜ì‚¬"]

    KEYWORDS_MARKET = ["ë§ˆê°ì‹œí™©", "ë§ˆê° ì‹œí™©"]

    

    EXCLUDES = ["ì„ ë´¬", "ë¶€ê³ ", "ë°°íƒ€ì ", "ìƒí’ˆ", "ê°„ë³‘", "ì‚¬ì—…ë¹„", "ë³´í—˜ê¸ˆ", "ì—°ê¸ˆë³´í—˜", "ë¯¼ì›", "ì¶œì‹œ", "ì†í•´ì‚¬ì •", "ì±„ë„ ê²½ìŸ", "ë¹„ê¸‰ì—¬", "ì›ë¦¬ê¸ˆ","ë³´ì¥í˜•","IRP"]

    EXCLUDES2 = []



    if "API_ID" in NAVER_CLIENT_ID:

        print("âš ï¸ ì„¤ì • ì˜¤ë¥˜: ì†ŒìŠ¤ì½”ë“œ ìƒë‹¨ì˜ API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")

    else:

        # ------------------------------------------------

        # 2. ê·¸ë£¹ë³„ ë¶„ë¦¬ ìˆ˜ì§‘ ì‹¤í–‰

        # ------------------------------------------------

        

        # A. ë³´í—˜ ë‰´ìŠ¤: ë„‰ë„‰í•˜ê²Œ 60ê°œ ìˆ˜ì§‘

        news_insurance = crawl_naver_news_api(KEYWORDS_INSURANCE, excludes=EXCLUDES, display_limit=60)

        

        # B. ì‹œí™© ë‰´ìŠ¤: 10ê°œë§Œ ìˆ˜ì§‘ í›„ -> â˜…ìµœì‹  3ê°œë§Œ ìë¥´ê¸°â˜…

        news_market = crawl_naver_news_api(KEYWORDS_MARKET, excludes=EXCLUDES2, display_limit=10)

        news_market = news_market[:3] # [í•µì‹¬] ì—¬ê¸°ì„œ ë”± 3ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤.

        print(f"   âœ‚ï¸ ì‹œí™© ë‰´ìŠ¤ëŠ” ìµœì‹  3ê°œë§Œ ë‚¨ê¸°ê³  ì˜ëìŠµë‹ˆë‹¤.")



        # ------------------------------------------------

        # 3. ê²°ê³¼ í•©ì¹˜ê¸° ë° ì „ì²´ ì¤‘ë³µ ì œê±°

        # ------------------------------------------------

        combined_list = news_insurance + news_market

        final_list = remove_duplicates_globally(combined_list)

        

        # ------------------------------------------------

        # 4. ë¦¬í¬íŠ¸ ì‘ì„± ë° ì „ì†¡

        # ------------------------------------------------

        final_msg = format_news_report(final_list)

        

        print("-" * 30)

        print(final_msg)

        print("-" * 30)

        

        send_telegram(final_msg)

