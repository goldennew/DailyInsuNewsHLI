import requests
from bs4 import BeautifulSoup
import time
import os
from datetime import datetime
import random

import requests
from bs4 import BeautifulSoup
import time
import os
from datetime import datetime
import random
from urllib.parse import quote  # í•œê¸€ ì¸ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

def crawl_naver_news_robust(keywords, pages=2):
    session = requests.Session()
    
    # ìµœì‹  ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í—¤ë”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Linux; Android 13; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    }

    try:
        session.get("https://m.naver.com", headers=headers, timeout=10)
    except:
        pass

    results = []
    query = " ".join(keywords)
    # í•œê¸€ ê²€ìƒ‰ì–´ë¥¼ URL ì•ˆì „í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    encoded_query = quote(query)
    
    print(f"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {query}")

    base_url = "https://m.search.naver.com/search.naver"

    for page in range(pages):
        start = (page * 15) + 1
        params = {
            'where': 'm_news',
            'query': query, # paramsì— ë„£ì„ ë•ŒëŠ” requestsê°€ ì•Œì•„ì„œ ì¸ì½”ë”©í•˜ì§€ë§Œ
            'sm': 'mtb_pge',
            'sort': '1',
            'nso': 'so:dd,p:2d',
            'start': start
        }

        # í—¤ë”ì˜ Refererì—ëŠ” ì§ì ‘ ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ ë„£ì–´ì¤˜ì•¼ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        headers['Referer'] = f"https://m.search.naver.com/search.naver?where=m_news&query={encoded_query}"

        try:
            time.sleep(random.uniform(1.5, 2.5))
            
            # ì—¬ê¸°ì„œ headersì— ì¸ì½”ë”©ëœ Refererê°€ í¬í•¨ë˜ì–´ ì—ëŸ¬ë¥¼ ë°©ì§€í•¨
            response = session.get(base_url, headers=headers, params=params, timeout=15)
            
            if response.status_code != 200:
                print(f"âŒ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœì½”ë“œ: {response.status_code})")
                continue

            if "ë¡œë´‡" in response.text or "CAPTCHA" in response.text:
                print("ğŸš¨ ë„¤ì´ë²„ ì°¨ë‹¨ ê°ì§€: IPê°€ ì œí•œë˜ì—ˆê±°ë‚˜ ë´‡ìœ¼ë¡œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break

            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = soup.select("li.bx") 

            found_in_page = 0
            for item in news_items:
                title_tag = item.select_one("a.news_tit")
                if not title_tag: continue
                
                text = title_tag.get_text().strip()
                href = title_tag.get('href')

                if 10 < len(text) < 100 and href.startswith("http"):
                    if any(r['url'] == href for r in results): continue
                    results.append({'title': text, 'url': href})
                    found_in_page += 1

            print(f"ğŸ“„ {page+1}í˜ì´ì§€: {found_in_page}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            if found_in_page == 0: break

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            break

    return results

# ... (ì´í›„ format_news_report ë° send_telegram í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)

def format_news_report(news_data):
    sector_invest = []   # <íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>
    sector_industry = [] # <ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>

    for item in news_data:
        title = item['title']
        if any(keyword in title for keyword in ['ì†ìµ', 'ìì‚°', 'ê¸ˆìœµ', 'ì‹œì¥', 'íˆ¬ì']):
            if len(sector_invest) < 5: sector_invest.append(item)
        else:
            if len(sector_industry) < 5: sector_industry.append(item)
    
    today = datetime.now().strftime("%Y-%m-%d")
    report = f"â–  News feed: {today}\n"
    
    report += "\n<ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>\n"
    if not sector_industry: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_industry:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    report += "<íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>\n"
    if not sector_invest: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_invest:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    return report

def send_telegram(message):
    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHAT_ID')
    if not token or not chat_id: 
        print("Telegram ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    try:
        requests.post(f"https://api.telegram.org/bot{token}/sendMessage", 
                      data={'chat_id': chat_id, 'text': message, 'disable_web_page_preview': True})
    except: pass

if __name__ == "__main__":
    KEYWORDS = ["ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…"]
    news_list = crawl_naver_news_robust(KEYWORDS, pages=2)
    final_msg = format_news_report(news_list)
    print(final_msg)
    send_telegram(final_msg)
