import requests
from bs4 import BeautifulSoup
import time
import os
from datetime import datetime

def crawl_naver_news_robust(keywords, pages=3):
    # ê¹ƒí—ˆë¸Œ IP ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´ ëª¨ë°”ì¼ ì£¼ì†Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    base_url = "https://m.search.naver.com/search.naver"
    
    # ë” ì‹¤ì œ ë¸Œë¼ìš°ì € ê°™ì€ í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ko-kr',
        'Referer': 'https://m.naver.com/'
    }

    results = []
    # ê²€ìƒ‰ì–´ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ ê°„ë‹¨í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    query = " ".join(keywords)
    print(f"ğŸ” ëª¨ë°”ì¼ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {query}")

    for page in range(pages):
        start = (page * 15) + 1
        params = {
            'where': 'm_news',
            'query': query,
            'sm': 'mtb_opt',
            'sort': '1', # ìµœì‹ ìˆœ
            'nso': 'so:dd,p:2d' # ìµœê·¼ 2ì¼
        }

        try:
            response = requests.get(base_url, headers=headers, params=params, timeout=15)
            
            # [ë””ë²„ê¹…] ë§Œì•½ ì°¨ë‹¨ë‹¹í–ˆë‹¤ë©´ ë¡œê·¸ì— ê¸°ë¡ë¨
            if response.status_code != 200:
                print(f"âŒ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœì½”ë“œ: {response.status_code})")
                continue

            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ëª¨ë°”ì¼ ë„¤ì´ë²„ ë‰´ìŠ¤ ì œëª© íƒœê·¸ ì¶”ì¶œ
            # ëª¨ë°”ì¼ì€ api_txt_lines tit ë˜ëŠ” news_tit í´ë˜ìŠ¤ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            news_items = soup.select("div.news_wrap")
            if not news_items:
                # ë‹¤ë¥¸ êµ¬ì¡°ì¼ ê²½ìš° ëŒ€ë¹„
                news_items = soup.select("li.bx")

            found_in_page = 0
            for item in news_items:
                title_tag = item.select_one("a.news_tit") or item.select_one("div.api_txt_lines.tit")
                if not title_tag: continue
                
                text = title_tag.get_text().strip()
                href = title_tag.get('href') if title_tag.has_attr('href') else title_tag.parent.get('href')

                # í•„í„°ë§: ì œëª© ê¸¸ì´ 10~100ì (ì‚¬ìš©ì ìš”ì²­)
                if 10 < len(text) < 100 and href and href.startswith("http"):
                    # ì¤‘ë³µ í™•ì¸
                    if any(r['url'] == href for r in results): continue
                    
                    results.append({'title': text, 'url': href})
                    found_in_page += 1

            print(f"ğŸ“„ {page+1}í˜ì´ì§€: {found_in_page}ê±´ ë°œê²¬")
            if found_in_page == 0:
                # ê¸°ì‚¬ê°€ ì „í˜€ ì—†ë‹¤ë©´ êµ¬ì¡°ê°€ ë°”ë€Œì—ˆê±°ë‚˜ ì°¨ë‹¨ëœ ê²ƒì´ë¯€ë¡œ ë¡œê·¸ ì¶œë ¥
                if "ë¡œë´‡" in response.text or "CAPTCHA" in response.text:
                    print("ğŸš¨ ë„¤ì´ë²„ê°€ ìë™ ìˆ˜ì§‘ì„ ê°ì§€í•˜ì—¬ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                break
            
            time.sleep(1.5) # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ì¡°ê¸ˆ ë” ì²œì²œíˆ

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            break

    return results

def format_news_report(news_data):
    sector_invest = []   # <íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>
    sector_industry = [] # <ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>

    for item in news_data:
        title = item['title']
        # 'ì†ìµ' ë˜ëŠ” 'ìì‚°' í¬í•¨ ì—¬ë¶€ë¡œ ì„¹í„° ë¶„ë¥˜
        if 'ì†ìµ' in title or 'ìì‚°' in title:
            if len(sector_invest) < 5: sector_invest.append(item)
        else:
            if len(sector_industry) < 5: sector_industry.append(item)
    
    today = datetime.now().strftime("%Y-%m-%d")
    report = f"â– News feed: {today}\n"
    
    report += "\n<ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>\n\n"
    if not sector_industry: report += "(ê¸°ì‚¬ ì—†ìŒ)\n\n"
    for item in sector_industry:
        report += f"{item['title']}\n{item['url']}\n\n"
        
    report += "<íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>\n\n"
    if not sector_invest: report += "(ê¸°ì‚¬ ì—†ìŒ)\n\n"
    for item in sector_invest:
        report += f"{item['title']}\n{item['url']}\n\n"
        
    return report

def send_telegram(message):
    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHAT_ID')
    if not token or not chat_id: return
    try:
        requests.post(f"https://api.telegram.org/bot{token}/sendMessage", 
                      data={'chat_id': chat_id, 'text': message, 'disable_web_page_preview': True})
    except: pass

if __name__ == "__main__":
    # ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë„ˆë¬´ ë³µì¡í•˜ê²Œ ì„ì§€ ë§ê³  í•µì‹¬ ìœ„ì£¼ë¡œ ë°°ì¹˜
    KEYWORDS = ["ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ë³´í—˜ì‚¬"]
    
    # ìˆ˜ì§‘ ì‹œì‘
    news_list = crawl_naver_news_robust(KEYWORDS, pages=3)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    final_msg = format_news_report(news_list)
    
    # ì¶œë ¥ ë° ì „ì†¡
    print(final_msg)
    send_telegram(final_msg)
