import requests
from bs4 import BeautifulSoup
import time
import os
from datetime import datetime
import random

def crawl_naver_news_robust(keywords, pages=2):
    # 1. ì„¸ì…˜ ê°ì²´ ìƒì„± (ì¿ í‚¤ ìœ ì§€ë¥¼ ìœ„í•¨)
    session = requests.Session()
    
    # 2. ìµœì‹  ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (Linux; Android 13; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Cache-Control': 'max-age=0',
        'Connection': 'keep-alive'
    }

    # 3. ë¨¼ì € ë„¤ì´ë²„ ëª¨ë°”ì¼ í™ˆì— ì ‘ì†í•˜ì—¬ ê¸°ë³¸ ì¿ í‚¤ë¥¼ êµ¬ì›€
    try:
        session.get("https://m.naver.com", headers=headers, timeout=10)
    except:
        pass

    results = []
    query = " ".join(keywords)
    print(f"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {query}")

    base_url = "https://m.search.naver.com/search.naver"

    for page in range(pages):
        # ê²€ìƒ‰ ê²°ê³¼ì˜ ì‹œì‘ ë²ˆí˜¸ (ëª¨ë°”ì¼ ê¸°ì¤€ í˜ì´ì§€ë‹¹ ì•½ 15~20ê°œ ë‚´ì™¸)
        start = (page * 15) + 1
        params = {
            'where': 'm_news',
            'query': query,
            'sm': 'mtb_pge',
            'sort': '1',      # ìµœì‹ ìˆœ
            'nso': 'so:dd,p:2d', # ìµœê·¼ 2ì¼
            'start': start
        }

        # Refererë¥¼ ë„¤ì´ë²„ ê²€ìƒ‰ ë©”ì¸ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìœ ì… ì—°ì¶œ
        headers['Referer'] = f"https://m.search.naver.com/search.naver?where=m_news&query={query}"

        try:
            # 0.5~2ì´ˆ ì‚¬ì´ì˜ ëœë¤ ì§€ì—° (ìë™í™” íƒì§€ ë°©ì§€)
            time.sleep(random.uniform(1.0, 2.5))
            
            response = session.get(base_url, headers=headers, params=params, timeout=15)
            
            if response.status_code != 200:
                print(f"âŒ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœì½”ë“œ: {response.status_code})")
                continue

            if "ë¡œë´‡" in response.text or "CAPTCHA" in response.text:
                print("ğŸš¨ ë„¤ì´ë²„ê°€ ìë™ ìˆ˜ì§‘ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜ IPë¥¼ ë³€ê²½í•˜ì„¸ìš”.")
                break

            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ëª¨ë°”ì¼ ë„¤ì´ë²„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ
            news_items = soup.select("li.bx") 

            found_in_page = 0
            for item in news_items:
                # ì œëª©ê³¼ ë§í¬ê°€ í¬í•¨ëœ íƒœê·¸ ì°¾ê¸°
                title_tag = item.select_one("a.news_tit")
                if not title_tag:
                    continue
                
                text = title_tag.get_text().strip()
                href = title_tag.get('href')

                # í•„í„°ë§ ì¡°ê±´ (ì œëª© ê¸¸ì´ ë° URL ì—¬ë¶€)
                if 10 < len(text) < 100 and href.startswith("http"):
                    if any(r['url'] == href for r in results): 
                        continue
                    
                    results.append({'title': text, 'url': href})
                    found_in_page += 1

            print(f"ğŸ“„ {page+1}í˜ì´ì§€: {found_in_page}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¤‘ë‹¨
            if found_in_page == 0:
                break

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            break

    return results

# ... (ì´í›„ format_news_report ë° send_telegram í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)

def format_news_report(news_data):
    sector_invest = []   # <íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>
    sector_industry = [] # <ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>

    for item in news_data:
        title = item['title']
        if any(keyword in title for keyword in ['ì†ìµ', 'ìì‚°', 'ê¸ˆìœµ', 'ì‹œì¥', 'íˆ¬ì']):
            if len(sector_invest) < 5: sector_invest.append(item)
        else:
            if len(sector_industry) < 5: sector_industry.append(item)
    
    today = datetime.now().strftime("%Y-%m-%d")
    report = f"â–  News feed: {today}\n"
    
    report += "\n<ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>\n"
    if not sector_industry: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_industry:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    report += "<íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>\n"
    if not sector_invest: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_invest:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    return report

def send_telegram(message):
    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHAT_ID')
    if not token or not chat_id: 
        print("Telegram ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    try:
        requests.post(f"https://api.telegram.org/bot{token}/sendMessage", 
                      data={'chat_id': chat_id, 'text': message, 'disable_web_page_preview': True})
    except: pass

if __name__ == "__main__":
    KEYWORDS = ["ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…"]
    news_list = crawl_naver_news_robust(KEYWORDS, pages=2)
    final_msg = format_news_report(news_list)
    print(final_msg)
    send_telegram(final_msg)
