import requests
import os
import html
import difflib
import time
from datetime import datetime

# ==========================================
# ğŸ”‘ API í‚¤ ì„¤ì •
# ==========================================
# (ë³´ì•ˆì„ ìœ„í•´ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ì˜ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”)
NAVER_CLIENT_ID = "2cC4xeZPfKKs3BVY_onT"
NAVER_CLIENT_SECRET = "21DmUYrAdX"

if os.environ.get("NAVER_CLIENT_ID"):
    NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
    NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

def crawl_naver_news_api(target_keywords, excludes=[], display_limit=50, category_tag='general'):
    """
    category_tag: 'insurance' ë˜ëŠ” 'market' ë“± ê¸°ì‚¬ì˜ ì„±ê²©ì„ êµ¬ë¶„í•˜ëŠ” íƒœê·¸ ì¶”ê°€
    """
    url = "https://openapi.naver.com/v1/search/news.json"
    
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    query = " | ".join(target_keywords)
    print(f"ğŸ” [{category_tag}] ê²€ìƒ‰ ì‹œì‘: {query} (ìš”ì²­ {display_limit}ê±´)")

    results = []
    
    loop_count = (display_limit // 100) + 1 if display_limit % 100 != 0 else (display_limit // 100)
    
    for i in range(loop_count):
        req_display = 100 if display_limit > 100 else display_limit
        display_limit -= req_display
        
        start = (i * 100) + 1
        
        params = {
            "query": query,
            "display": req_display,
            "start": start,
            "sort": "date"
        }

        try:
            response = requests.get(url, headers=headers, params=params)
            if response.status_code != 200:
                print(f"âŒ API í˜¸ì¶œ ì—ëŸ¬: {response.status_code}")
                break

            items = response.json().get('items', [])
            if not items: break

            for item in items:
                raw_title = item['title']
                clean_title = html.unescape(raw_title).replace("<b>", "").replace("</b>", "")
                
                raw_desc = item['description']
                clean_desc = html.unescape(raw_desc).replace("<b>", "").replace("</b>", "")
                
                link = item['originallink'] if item['originallink'] else item['link']

                # 1. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
                if any(ex_word in clean_title for ex_word in excludes):
                    continue

                # 2. í•„ìˆ˜ í‚¤ì›Œë“œ ì²´í¬ (ì œëª© ê¸°ì¤€)
                if not any(key_word in clean_title for key_word in target_keywords):
                    continue
                
                # [ìˆ˜ì •] ê²°ê³¼ì— ì¹´í…Œê³ ë¦¬ íƒœê·¸ ì¶”ê°€
                results.append({
                    'title': clean_title, 
                    'url': link, 
                    'desc': clean_desc,
                    'category': category_tag 
                })
            
            time.sleep(0.3) 

        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬: {e}")
            break
            
    print(f"   ğŸ‘‰ [{category_tag}] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
    return results

def remove_duplicates_globally(all_news):
    """
    categoryë³„ë¡œ ë‹¤ë¥¸ ê¸€ì ìˆ˜ ì œí•œì„ ì ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°
    - Market: 30ì ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µ
    - Insurance: 15ì ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µ
    """
    unique_news = []
    seen_urls = set()
    seen_descriptions = []

    print("ğŸ§¹ ì „ì²´ ì¤‘ë³µ ì œê±° ì‘ì—… ì¤‘... (Market: 30ì / Insurance: 15ì)")

    for item in all_news:
        # 1. URL ì¤‘ë³µ ì²´í¬
        if item['url'] in seen_urls:
            continue
            
        # 2. ë³¸ë¬¸ ë‚´ìš© ìœ ì‚¬ë„ ì²´í¬
        category = item.get('category', 'general')
        
        # [í•µì‹¬ ë¡œì§ ë³€ê²½] ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ê¸°ì¤€ ê¸€ì ìˆ˜(threshold) ë‹¤ë¥´ê²Œ ì„¤ì •
        if category == 'market':
            threshold = 60  # ì‹œí™©ì€ ìƒíˆ¬ì ì¸ ë¬¸êµ¬ê°€ ë§ìœ¼ë¯€ë¡œ 30ìê¹Œì§€ í—ˆìš©
        else:
            threshold = 12  # ë³´í—˜ì€ 15ìë§Œ ê²¹ì³ë„ ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬
            
        is_content_dup = False
        for exist_desc in seen_descriptions:
            matcher = difflib.SequenceMatcher(None, item['desc'], exist_desc)
            match = matcher.find_longest_match(0, len(item['desc']), 0, len(exist_desc))
            
            if match.size >= threshold: 
                is_content_dup = True
                break
        
        if is_content_dup:
            continue

        seen_urls.add(item['url'])
        seen_descriptions.append(item['desc'])
        unique_news.append(item)

    print(f"âœ… ìµœì¢… ë¦¬í¬íŠ¸ í¬í•¨ ê¸°ì‚¬: {len(unique_news)}ê±´")
    return unique_news

def format_news_report(news_data):
    sector_invest = []   # <íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>
    sector_industry = [] # <ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>

    for item in news_data:
        title = item['title']
        
        # íˆ¬ì/ì‹œì¥ ì„¹í„°ë¡œ ë³´ë‚¼ í‚¤ì›Œë“œ
        invest_keywords = ['ì†ìµ', 'ì‹¤ì ', 'IR', 'ë‰´ìš•ì¦ì‹œ', 'ì½”ìŠ¤í”¼', 'ë§ˆê°', 'ì‹œí™©', 'ì£¼ê°€', 'ì¦ì‹œ']
        
        if any(k in title for k in invest_keywords):
            sector_invest.append(item)
        else:
            sector_industry.append(item)
    
    today = datetime.now().strftime("%Y-%m-%d")
    report = f"â–  News feed: {today}\n"
    
    report += "\n<ìƒë³´3ì‚¬/ë³´í—˜ì—…ê³„>\n"
    if not sector_industry: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_industry:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    report += "<íˆ¬ìì†ìµ/ê¸ˆìœµì‹œì¥>\n"
    if not sector_invest: report += "(ê¸°ì‚¬ ì—†ìŒ)\n"
    for item in sector_invest:
        report += f"â€¢ {item['title']}\n{item['url']}\n\n"
        
    return report

def send_telegram(message):
    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHAT_ID')
    
    if not token or not chat_id:
        print("ğŸ”” í…”ë ˆê·¸ë¨ ì„¤ì • ì—†ìŒ (ì½˜ì†” ì¶œë ¥)")
        return

    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        data = {
            'chat_id': chat_id, 
            'text': message, 
            'disable_web_page_preview': True
        }
        requests.post(url, data=data)
        print("ğŸš€ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ------------------------------------------------
    # 1. í‚¤ì›Œë“œ ê·¸ë£¹ ì •ì˜
    # ------------------------------------------------
    KEYWORDS_INSURANCE = ["ì‚¼ì„±ìƒëª…", "í•œí™”ìƒëª…", "êµë³´ìƒëª…", "ìƒë³´ì‚¬", "ë³´í—˜ì‚¬"]
    
    # [Tip] ì‹œí™© ë‰´ìŠ¤ê°€ ì˜ ì•ˆ ì¡íˆë©´ ì•„ë˜ í‚¤ì›Œë“œë¥¼ "ì¦ì‹œ", "ì½”ìŠ¤í”¼" ë“±ìœ¼ë¡œ ì¡°ê¸ˆ ë” ë„“íˆëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤.
    KEYWORDS_MARKET = ["ë§ˆê°ì‹œí™©", "ë§ˆê° ì‹œí™©", "ë‰´ìš•ì¦ì‹œ","ì½”ìŠ¤í”¼"] 
    
    EXCLUDES = ["ë¶€ê³ ", "ë°°íƒ€ì ", "ìƒí’ˆ", "ê°„ë³‘", "ì‚¬ì—…ë¹„", "ë³´í—˜ê¸ˆ", "ì—°ê¸ˆë³´í—˜", "ë¯¼ì›", "ì¶œì‹œ", "ì†í•´ì‚¬ì •", "ì±„ë„ ê²½ìŸ", "ë¹„ê¸‰ì—¬", "ì›ë¦¬ê¸ˆ","ë³´ì¥í˜•","IRP"]
    EXCLUDES2 = []

    if "YOUR_CLIENT_ID" in NAVER_CLIENT_ID: # ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ ì²´í¬
         print("âš ï¸ ì„¤ì • ì˜¤ë¥˜: ì†ŒìŠ¤ì½”ë“œ ìƒë‹¨ì˜ API í‚¤ë¥¼ ë³¸ì¸ì˜ í‚¤ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.")
    else:
        # ------------------------------------------------
        # 2. ê·¸ë£¹ë³„ ë¶„ë¦¬ ìˆ˜ì§‘ ì‹¤í–‰ (category_tag ì¶”ê°€)
        # ------------------------------------------------
        
        # A. ë³´í—˜ ë‰´ìŠ¤ (íƒœê·¸: insurance)
        news_insurance = crawl_naver_news_api(
            KEYWORDS_INSURANCE, 
            excludes=EXCLUDES, 
            display_limit=60, 
            category_tag='insurance'
        )
        
        # B. ì‹œí™© ë‰´ìŠ¤ (íƒœê·¸: market) -> ìµœì‹  3ê°œë§Œ ìë¥´ê¸°
        news_market = crawl_naver_news_api(
            KEYWORDS_MARKET, 
            excludes=EXCLUDES2, 
            display_limit=20, 
            category_tag='market'
        )
        news_market = news_market[:3] 
        print(f"   âœ‚ï¸ ì‹œí™© ë‰´ìŠ¤ëŠ” ìµœì‹  3ê°œë§Œ ë‚¨ê¸°ê³  ì˜ëìŠµë‹ˆë‹¤.")

        # ------------------------------------------------
        # 3. ê²°ê³¼ í•©ì¹˜ê¸° ë° ì°¨ë“± ì¤‘ë³µ ì œê±°
        # ------------------------------------------------
        combined_list = news_insurance + news_market
        final_list = remove_duplicates_globally(combined_list)
        
        # ------------------------------------------------
        # 4. ë¦¬í¬íŠ¸ ì‘ì„± ë° ì „ì†¡
        # ------------------------------------------------
        final_msg = format_news_report(final_list)
        
        print("-" * 30)
        print(final_msg)
        print("-" * 30)
        
        send_telegram(final_msg)
